{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas\n",
    "import numpy\n",
    "import glob\n",
    "import math\n",
    "import tqdm\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with open(file) as f:\n",
    "    for line in f:\n",
    "        separated = line.strip().split(\" \")\n",
    "        sep1 = itertools.islice(separated, 0, None, 2)\n",
    "        sep2 = itertools.islice(separated, 1, None, 2)\n",
    "        _dict = dict(zip(sep1, sep2))\n",
    "        results.append(_dict)\n",
    "        \n",
    "results = pandas.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"name\"] = results[\"name\"].convert_dtypes()\n",
    "results[\"tag\"] = results[\"tag\"].convert_dtypes()\n",
    "results[\"--nIterations\"] = results[\"--nIterations\"].astype(\"Int64\")\n",
    "results[\"--nActors\"] = results[\"--nActors\"].astype(\"Int64\")\n",
    "results[\"--sWorkload\"] = results[\"--sWorkload\"].convert_dtypes()\n",
    "results[\"--nEvents\"] = results[\"--nEvents\"].astype(\"Int64\")\n",
    "results[\"--sSystem\"] = results[\"--sSystem\"].convert_dtypes()\n",
    "results[\"average(s)\"] = results[\"average(s)\"].astype(\"float64\")\n",
    "results[\"--nChainLength\"] = results[\"--nChainLength\"].astype(\"Int64\")\n",
    "results[\"--nAtomSize\"] = results[\"--nAtomSize\"].astype(\"Int64\")\n",
    "results[\"--nWorkflows\"] = results[\"--nWorkflows\"].astype(\"Int64\")\n",
    "results[\"--nParallelism\"] = results[\"--nParallelism\"].astype(\"Int64\")\n",
    "results[\"--nPartitions\"] = results[\"--nPartitions\"].astype(\"Int64\")\n",
    "results[\"--sQuery\"] = results[\"--sQuery\"].convert_dtypes()\n",
    "results.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tag to name\n",
    "results[\"full-name\"] = results[\"tag\"].fillna('') + results[\"name\"].fillna('')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"average-throughput (events/s)\"] = results[\"--nEvents\"] / results[\"average(s)\"]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"full-name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styles Mapping\n",
    "\n",
    "colours = [\"r\", \"g\", \"b\", \"c\", \"y\"]\n",
    "markers = [\"o\", \"v\", \"^\", \"x\", \"p\"]\n",
    "linestyles = ['-','--',':','-.','']\n",
    "linewidths = [3, 2, 1, 1, 0.5]\n",
    "hatches = ['/', '\\\\', '|', '-', '+', 'x', 'o', 'O', '.', '*']\n",
    "\n",
    "sSystems = [\"async\", \"microBatching\", \"noGuarantees\", \"sync\", \"Akka\"]\n",
    "\n",
    "s_colours = dict(zip(sSystems, colours))\n",
    "s_markers = dict(zip(sSystems, markers))\n",
    "s_linestyles = dict(zip(sSystems, linestyles))\n",
    "s_linewidths = dict(zip(sSystems, linewidths))\n",
    "s_hatches = dict(zip(sSystems, hatches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line chart\n",
    "\n",
    "def plot_line(\n",
    "    name,\n",
    "    benchmarks,\n",
    "    filter_col,\n",
    "    group_cols,\n",
    "    x_axis,\n",
    "    y_axis,\n",
    "    x_label,\n",
    "    y_label,\n",
    "    log_scale_y = False,\n",
    "    log_scale_x = False,\n",
    "    ignore_cols = [],\n",
    "    ignore_vals = [],\n",
    "    filename = \"\",\n",
    "    withUnnamedStyles = False,\n",
    "):\n",
    "    \n",
    "    plt.figure(figsize=(1.618 * 3, 3))\n",
    "\n",
    "    filtered = results[results[filter_col].isin(benchmarks)]\n",
    "    \n",
    "    if ignore_cols != []:\n",
    "        filtered = filtered[~filtered[ignore_cols].isin(ignore_vals).values]\n",
    "\n",
    "    grouped = filtered.groupby(group_cols)\n",
    "\n",
    "    # Plotting\n",
    "    for i, (_label, df) in enumerate(grouped):\n",
    "        label = _label[1]\n",
    "        x = df[x_axis]\n",
    "        y = df[y_axis]\n",
    "        \n",
    "        if not withUnnamedStyles:\n",
    "            marker = s_markers[label]\n",
    "            linestyle = s_linestyles[label]\n",
    "            colour = s_colours[label]\n",
    "            linewidth = s_linewidths[label]\n",
    "            plt.plot(x, y, label=label, marker=marker, ls=linestyle, c=colour, linewidth=linewidth)\n",
    "        else:\n",
    "            marker = markers[i]\n",
    "            linestyle = linestyles[i]\n",
    "            colour = colours[i]\n",
    "            linewidth = linewidths[i]\n",
    "            plt.plot(x, y, label=label, marker=marker, ls=linestyle, c=colour, linewidth=linewidth)\n",
    "\n",
    "    # formatting\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.title(name)\n",
    "    plt.grid(which=\"both\", linestyle='--')\n",
    "    plt.tick_params(which='minor', color='r')\n",
    "    plt.legend()\n",
    "\n",
    "    if log_scale_y: plt.yscale(\"log\")\n",
    "    if log_scale_x: plt.xscale(\"log\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.ylim(bottom=0)\n",
    "\n",
    "    if filename != \"\": plt.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar chart\n",
    "\n",
    "def plot_bar(\n",
    "    name,\n",
    "    benchmarks,\n",
    "    filter_col,\n",
    "    group_cols,\n",
    "    y_axis,\n",
    "    y_label,\n",
    "    x_label,\n",
    "    log_scale_y = False,\n",
    "    ignore_cols = [],\n",
    "    ignore_vals = [],\n",
    "    translation = dict(),\n",
    "    filename = \"\",\n",
    "):\n",
    "    plt.figure(figsize=(1.618 * 3, 3))\n",
    "    filtered = results[results[filter_col].isin(benchmarks)]\n",
    "    if ignore_cols != []:\n",
    "        filtered = filtered[~filtered[ignore_cols].isin(ignore_vals).values]\n",
    "    grouped = filtered.groupby(group_cols)\n",
    "    \n",
    "    from collections import OrderedDict\n",
    "\n",
    "    groupss = dict(list(grouped))\n",
    "    outer_groups = [x[0] for x in groupss.keys()]\n",
    "    groupedgroups = list(OrderedDict.fromkeys(outer_groups))\n",
    "    \n",
    "    n = len(groupedgroups) # number of outer groups\n",
    "    n_inner = len(groupss) / len(groupedgroups) # number of inner groups\n",
    "    width=(n_inner - 1.0)/n_inner \n",
    "#     barwidth=0.8/n_inner\n",
    "\n",
    "    for i, (_label, df) in enumerate(grouped):\n",
    "        label = _label[1]\n",
    "        \n",
    "        # style\n",
    "        marker = s_markers[label]\n",
    "        linestyle = s_linestyles[label]\n",
    "        colour = s_colours[label]\n",
    "        linewidth = s_linewidths[label]\n",
    "        hatch = s_hatches[label]\n",
    "\n",
    "        # data\n",
    "        y = df[y_axis]\n",
    "\n",
    "        # names, etc.\n",
    "        label = _label[1]\n",
    "\n",
    "        # plot\n",
    "        if i < n_inner:\n",
    "            plt.bar(i*width + math.floor((i) / n_inner)*(width), df[y_axis], width, align='center', label=label, ls=linestyle, color=colour, linewidth=linewidth, hatch=hatch)\n",
    "        else:\n",
    "            plt.bar(i*width + math.floor((i) / n_inner)*(width), df[y_axis], width, align='center', ls=linestyle, color=colour, linewidth=linewidth, hatch=hatch)\n",
    "        \n",
    "    x = numpy.arange(n)\n",
    "    if translation != dict():\n",
    "        plt.xticks(x*(n_inner+1)*width  + ((n_inner-1)*width/2.0), [translation[k] for k in groupedgroups])\n",
    "    else:\n",
    "        plt.xticks(x*(n_inner+1)*width  + ((n_inner-1)*width/2.0), groupedgroups)\n",
    "    # formatting\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.title(name)\n",
    "    plt.grid(which=\"both\", linestyle='--', axis=\"y\")\n",
    "    plt.legend()\n",
    "    if log_scale_y: plt.yscale(\"log\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if filename != \"\": plt.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXMarkBenchmark\n",
    "plot_bar(\n",
    "    name = \"NEXMark\",\n",
    "    benchmarks = [\"NEXMarkBenchmark\"],\n",
    "    filter_col = \"full-name\",\n",
    "    group_cols = [\"--sQuery\", \"--sSystem\"],\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"\",\n",
    "#     log_scale_y = True,\n",
    "    ignore_cols = [\"--sSystem\"],\n",
    "    ignore_vals = [\"sync\"],\n",
    "    filename = \"results/nexmark.pdf\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MICROBENCHMARKS\n",
    "\n",
    "# PingPong\n",
    "\n",
    "plot_bar(\n",
    "    name = \"PingPong\",\n",
    "    benchmarks = [\"PingPongBenchmark\"],\n",
    "    filter_col = \"full-name\",\n",
    "    group_cols = [\"full-name\", \"--sSystem\"],\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"\",\n",
    "#     log_scale_y = True,\n",
    "    ignore_cols = [\"--sSystem\"],\n",
    "    ignore_vals = [\"sync\"],\n",
    "    translation = {\"PingPongBenchmark\": \"PingPong\"},\n",
    "    filename = \"results/pingpongmicro.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MICROBENCHMARKS\n",
    "plot_line(\n",
    "    name = \"Thread Ring of Tasks\",\n",
    "    benchmarks = [\"ThreadRingTasks\"],\n",
    "    filter_col = \"full-name\",\n",
    "    group_cols = [\"full-name\", \"--sSystem\"],\n",
    "    x_axis = \"--nChainLength\",\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"chain length (no. of tasks)\",\n",
    "#     log_scale_y = True,\n",
    "    log_scale_x = True,\n",
    "    ignore_cols = [\"--sSystem\"],\n",
    "    ignore_vals = [\"sync\"],\n",
    "    filename = \"results/threadringmicro.pdf\",\n",
    ")\n",
    "\n",
    "# no figure saved\n",
    "plot_line(\n",
    "    name = \"Thread Ring of Workflows\",\n",
    "    benchmarks = [\"ThreadRingWorkflows\"],\n",
    "    filter_col = \"full-name\",\n",
    "    group_cols = [\"full-name\", \"--sSystem\"],\n",
    "    x_axis = \"--nChainLength\",\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"chain length (no. of workflows)\",\n",
    "#     log_scale_y = True,\n",
    "    log_scale_x = True,\n",
    "    ignore_cols = [\"--sSystem\"],\n",
    "    ignore_vals = [\"sync\"],\n",
    ")\n",
    "\n",
    "plot_line(\n",
    "    name = \"Thread Ring of Alternating Workflows\",\n",
    "    benchmarks = [\"ThreadRingWorkflowsAlternatingSequencers\"],\n",
    "    filter_col = \"full-name\", \n",
    "    group_cols = [\"full-name\", \"--sSystem\"],\n",
    "    x_axis = \"--nChainLength\",\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"chain length (no. of workflows)\",\n",
    "#     log_scale_y = True,\n",
    "    log_scale_x = True,\n",
    "    ignore_cols = [\"--sSystem\"],\n",
    "    ignore_vals = [\"sync\"],\n",
    "    filename = \"results/threadringwfsmicro.pdf\",\n",
    ")\n",
    "\n",
    "plot_line(\n",
    "    name = \"Counting Actor\",\n",
    "    benchmarks = [\"CountingActorBenchmark\"],\n",
    "    filter_col = \"full-name\", \n",
    "    group_cols = [\"full-name\", \"--sSystem\"],\n",
    "    x_axis = \"--nAtomSize\",\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"atom size (#events)\",\n",
    "#     log_scale_y = True,\n",
    "    log_scale_x = True,\n",
    "    ignore_cols = [\"--sSystem\"],\n",
    "    ignore_vals = [\"sync\"],\n",
    "    filename = \"results/countingactormicro.pdf\",\n",
    ")\n",
    "\n",
    "\n",
    "plot_line(\n",
    "    name = \"Fork Join Throughput\",\n",
    "    benchmarks = [\"ForkJoinThroughputBenchmark\"],\n",
    "    filter_col = \"full-name\", \n",
    "    group_cols = [\"full-name\", \"--sSystem\"],\n",
    "    x_axis = \"--nWorkflows\",\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"fork-width (#workflows)\",\n",
    "#     log_scale_y = True,\n",
    "    log_scale_x = True,\n",
    "    ignore_cols = [\"--sSystem\"],\n",
    "    ignore_vals = [\"sync\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parallelism-threads, Data-parallelism\n",
    "\n",
    "plot_line(\n",
    "    name = \"Partitions\",\n",
    "    benchmarks = [\"partitionsDataParallelThroughputBenchmark\"],\n",
    "    filter_col = \"full-name\",    \n",
    "    group_cols = [\"full-name\", \"--sWorkload\"],\n",
    "    x_axis = \"--nPartitions\",\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    log_scale_x = True,\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"number of partitions\",\n",
    "    withUnnamedStyles=True,\n",
    "    filename = \"results/parallelismpartitions.pdf\",\n",
    ")\n",
    "\n",
    "plot_line(\n",
    "    name = \"Parallelism\",\n",
    "    benchmarks = [\"parallelismDataParallelThroughputBenchmark\"],\n",
    "    filter_col = \"full-name\",    \n",
    "    group_cols = [\"full-name\", \"--sWorkload\"],\n",
    "    x_axis = \"--nParallelism\",\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"number of threads\",\n",
    "    withUnnamedStyles=True,\n",
    "    filename = \"results/parallelismthreads.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = results[(results[\"full-name\"] == \"partitionsDataParallelThroughputBenchmark\") & (results[\"--sWorkload\"] == \"countingActor\")]\n",
    "pp = results[(results[\"full-name\"] == \"partitionsDataParallelThroughputBenchmark\") & (results[\"--sWorkload\"] == \"pingPong\")]\n",
    "tr = results[(results[\"full-name\"] == \"partitionsDataParallelThroughputBenchmark\") & (results[\"--sWorkload\"] == \"threadRingTasks\")]\n",
    "print(\n",
    "    ca[\"average-throughput (events/s)\"].max() / ca[\"average-throughput (events/s)\"].min(),\n",
    "    pp[\"average-throughput (events/s)\"].max() / pp[\"average-throughput (events/s)\"].min(),\n",
    "    tr[\"average-throughput (events/s)\"].max() / tr[\"average-throughput (events/s)\"].min(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = results[(results[\"full-name\"] == \"parallelismDataParallelThroughputBenchmark\") & (results[\"--sWorkload\"] == \"countingActor\")]\n",
    "pp = results[(results[\"full-name\"] == \"parallelismDataParallelThroughputBenchmark\") & (results[\"--sWorkload\"] == \"pingPong\")]\n",
    "tr = results[(results[\"full-name\"] == \"parallelismDataParallelThroughputBenchmark\") & (results[\"--sWorkload\"] == \"threadRingTasks\")]\n",
    "print(\n",
    "    ca[\"average-throughput (events/s)\"].max() / ca[\"average-throughput (events/s)\"].min(),\n",
    "    pp[\"average-throughput (events/s)\"].max() / pp[\"average-throughput (events/s)\"].min(),\n",
    "    tr[\"average-throughput (events/s)\"].max() / tr[\"average-throughput (events/s)\"].min(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# AtomAlignmentBenchmark\n",
    "\n",
    "plot_line(\n",
    "    name = \"Atom Alignment\",\n",
    "    benchmarks = [\"AtomAlignmentBenchmark\"],\n",
    "    filter_col = \"full-name\",    \n",
    "    group_cols = [\"full-name\", \"--sSystem\"],\n",
    "    x_axis = \"--nAtomSize\",\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"atom size (#events)\",\n",
    "    log_scale_x = True,\n",
    "    ignore_cols = [\"--sSystem\"],\n",
    "    ignore_vals = [\"sync\"],\n",
    "#     withUnnamedStyles=True,\n",
    "    filename = \"results/alignmentmicro.pdf\",\n",
    ")\n",
    "\n",
    "plot_line(\n",
    "    name = \"Atom Alignment With Work\",\n",
    "    benchmarks = [\"withWorkAtomAlignmentBenchmark\"],\n",
    "    filter_col = \"full-name\",    \n",
    "    group_cols = [\"full-name\", \"--sSystem\"],\n",
    "    x_axis = \"--nAtomSize\",\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"atom size (#events)\",\n",
    "    log_scale_x = True,\n",
    "#     withUnnamedStyles=True,\n",
    "    filename = \"results/alignmentmicrowithwork.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Akka benchmarks\n",
    "\n",
    "plot_bar(\n",
    "    name = \"Akka Benchmark\",\n",
    "    benchmarks = [\"AkkaBenchmarks\"],\n",
    "    filter_col = \"tag\",\n",
    "    group_cols = [\"--sWorkload\", \"--sSystem\"],\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"\",\n",
    "#     log_scale_y = True,\n",
    "#     ignore_cols = [\"--sSystem\"],\n",
    "#     ignore_vals = [\"sync\"],\n",
    "#     translation = {\"PingPongBenchmark\": \"PingPong\"},\n",
    "    filename = \"results/akkamicro.pdf\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChainOfTasks Benchmark\n",
    "\n",
    "plot_line(\n",
    "    name = \"Chain of Tasks\",\n",
    "    benchmarks = [\"--nChainLengthChainOfTasksWithWork\"],\n",
    "    filter_col = \"full-name\",    \n",
    "    group_cols = [\"full-name\", \"--sSystem\"],\n",
    "    x_axis = \"--nChainLength\",\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"chain length (#tasks)\",\n",
    "    log_scale_x = True,\n",
    "#     withUnnamedStyles=True,\n",
    "    filename = \"results/chainoftaskslength.pdf\",\n",
    ")\n",
    "\n",
    "plot_line(\n",
    "    name = \"Chain of Tasks\",\n",
    "    benchmarks = [\"--nAtomSizeChainOfTasksWithWork\"],\n",
    "    filter_col = \"full-name\",    \n",
    "    group_cols = [\"full-name\", \"--sSystem\"],\n",
    "    x_axis = \"--nAtomSize\",\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"atom size (#events)\",\n",
    "    log_scale_x = True,\n",
    "    filename = \"results/chainoftaskssize.pdf\",\n",
    "#     withUnnamedStyles=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results[\"tag\"] == \"syncbenchmark\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChainOfTasks Benchmark\n",
    "\n",
    "plot_bar(\n",
    "    name = \"MicroBenchmarks\",\n",
    "    benchmarks = [\"syncbenchmark\"],\n",
    "    filter_col = \"tag\",    \n",
    "    group_cols = [\"name\", \"--sSystem\"],\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"\",\n",
    "    ignore_cols = [\"name\"],\n",
    "    ignore_vals = [\"ChainOfTasksWithWork\", \"NEXMarkBenchmark\"],\n",
    "    translation = {\"CountingActorBenchmark\": \"CountingActor\", \"PingPongBenchmark\": \"PingPong\", \"ThreadRingTasks\": \"ThreadRing\"},\n",
    "    filename = \"results/syncmicros.pdf\",\n",
    ")\n",
    "\n",
    "plot_bar(\n",
    "    name = \"Chain of Tasks\",\n",
    "    benchmarks = [\"syncbenchmarkChainOfTasksWithWork\"],\n",
    "    filter_col = \"full-name\",    \n",
    "    group_cols = [\"name\", \"--sSystem\"],\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"\",\n",
    "#     ignore_cols = [\"name\"],\n",
    "#     ignore_vals = [\"ChainOfTasksWithWork\", \"NEXMarkBenchmark\"],\n",
    "    translation = {\"ChainOfTasksWithWork\": \"Chain of Tasks\"},\n",
    "    filename = \"results/syncchain.pdf\",\n",
    ")\n",
    "\n",
    "plot_bar(\n",
    "    name = \"NEXMark\",\n",
    "    benchmarks = [\"syncbenchmarkNEXMarkBenchmark\"],\n",
    "    filter_col = \"full-name\",    \n",
    "    group_cols = [\"--sQuery\", \"--sSystem\"],\n",
    "    y_axis = \"average-throughput (events/s)\",\n",
    "    y_label = \"throughput (events/s)\",\n",
    "    x_label = \"\",\n",
    "#     ignore_cols = [\"name\"],\n",
    "#     ignore_vals = [\"ChainOfTasksWithWork\", \"NEXMarkBenchmark\"],\n",
    "#     translation = {\"ChainOfTasksWithWork\": \"Chain of Tasks\"},\n",
    "    filename = \"results/syncnexmark.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = results[results[\"name\"].isin({\"DataParallelThroughputBenchmark\"})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = filtered[((filtered[\"--nParallelism\"] == 1) | (filtered[\"--nParallelism\"] == 16)) & (filtered[\"tag\"] == \"parallelism\")]\n",
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = filtered[((filtered[\"--nParallelism\"] == 1) | (filtered[\"--nParallelism\"] == 8)) & (filtered[\"tag\"] == \"parallelism\")]\n",
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xxx[(xxx[\"--nParallelism\"] == 8)][\"average-throughput (events/s)\"].values / xxx[(xxx[\"--nParallelism\"] == 1)][\"average-throughput (events/s)\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx[(xxx[\"--nParallelism\"] == 1)][\"average-throughput (events/s)\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = results[results[\"tag\"].isin({\"AkkaBenchmarks\"})]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered[ filtered[\"--sSystem\"] == \"Akka\"][\"average-throughput (events/s)\"].values / filtered[ filtered[\"--sSystem\"] == \"async\"][\"average-throughput (events/s)\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = results[results[\"name\"].isin({\"AtomAlignmentBenchmark\"})]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Akka Benchmarks\n",
    "tmp = results[results[\"tag\"].isin({\"AkkaBenchmarks\"})]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akka = tmp[tmp[\"--sSystem\"] == \"Akka\"]\n",
    "akkavals = akka[\"average-throughput (events/s)\"].values\n",
    "asnc = tmp[tmp[\"--sSystem\"] == \"async\"]\n",
    "asncvals = asnc[\"average-throughput (events/s)\"].values\n",
    "print(akkavals)\n",
    "print(asncvals)\n",
    "print(akkavals/asncvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results[\"name\"] == \"PingPongBenchmark\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[(results[\"name\"] == \"CountingActorBenchmark\") & (results[\"--nAtomSize\"] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
